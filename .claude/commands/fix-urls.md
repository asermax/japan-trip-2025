# Fix URLs Command

**Usage:** `/fix-urls [destination] [--routes] [--offset N] [--limit N]`

**Arguments:**
- `destination` (optional): Specific destination slug to check (e.g., `tokyo`, `kyoto`). Omit to check all files.
- `--routes` (optional): Check route files instead of attractions/destinations. Use with destination to filter by route name.
- `--offset N` (optional): Skip first N files
- `--limit N` (optional): Process only N files after offset

**Purpose:** Validate URLs in research files and fix broken ones using parallel agents to find working replacements.

## Command Workflow

### Phase 1: Detection & User Validation
1. Run `uv run python scripts/find_broken_urls.py [destination] [--routes] [--offset N] [--limit N]` to identify broken URLs
   - Script outputs grouped list of broken URLs by file
   - URLs grouped by file for easy review
   - Shows URL, error type, and context (link text)

2. **Present broken URLs to user for validation**
   - Show each broken URL with context (file, text, error)
   - Ask user to validate each URL (try opening in browser)
   - User confirms which URLs are truly broken vs false positives (e.g., HTTP 403 might still work in browser)

### Phase 2: Parallel Agent Replacement
1. For each **user-confirmed** broken URL, deploy a general-purpose agent
2. Run 3-5 agents in parallel (batch processing)
3. Each agent searches for replacement content:
   - Read the research file to understand the context
   - Identify what information the broken URL was providing
   - Search for working alternative sources:
     - Official websites (tourism boards, attraction sites)
     - Wikipedia and Wikimedia pages
     - Government sources and verified travel sites
     - Updated URLs if site structure changed
   - Return replacement URL with brief description of content

4. **Present replacement URLs to user for validation**
   - Show original context and proposed replacement
   - User validates replacement is appropriate
   - If rejected, agent searches for another option
   - Repeat until user approves replacement

### Phase 3: Update Files
1. Replace approved URLs in research files
2. Optionally regenerate site content with `uv run python scripts/generate_timeline.py`

## Agent Prompt Template
```
TASK: Find a working replacement URL for this broken citation.

File: [FILE_PATH]
Link text/context: [LINK_TEXT]
Current broken URL: [BROKEN_URL]
Error: [ERROR]

Steps:
1. Read the file to understand what information this URL was providing
2. Search for a working alternative source for the same information:
   - Official websites (tourism boards, attraction sites)
   - Wikipedia and Wikimedia pages
   - Government sources and verified travel sites
   - Updated URLs if site structure changed
3. Verify the new URL loads and contains relevant information

Return:
- New URL: [url]
- Content: [brief description of what this URL provides]
```

## URL Types Detected
- **Markdown links**: `[text](url)` - Any external links in content
- **Source citations**: `[ðŸ”—](url)` - Source attribution links
- **Skipped**: Internal links (`/`), anchors (`#`), email (`mailto:`)

## Error Categories
- **HTTP 4xx/5xx**: Page not found, server errors
- **Timeout**: Site not responding
- **Connection errors**: DNS failures, network issues
- **SSL errors**: Certificate problems
- **Too many redirects**: Redirect loops

## Implementation
- Use `scripts/find_broken_urls.py` for validation
- Deploy parallel Task agents for URL replacement
- Update research markdown files directly
- Optionally regenerate site content after fixes
